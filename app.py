import json
import os
import torch
from torch.utils.data import DataLoader
from flask import Flask, request, jsonify
import warnings

# === å¯¼å…¥ä½ çš„è‡ªå®šä¹‰æ¨¡å— ===
from EPERR import EPERR
import preprocess as process

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# === åˆå§‹åŒ– Flask åº”ç”¨ ===
app = Flask(__name__)

# === å…¨å±€å˜é‡ ===
# è¿™äº›å˜é‡å°†åœ¨æœåŠ¡å¯åŠ¨æ—¶åŠ è½½ï¼Œé¿å…æ¯æ¬¡è¯·æ±‚éƒ½é‡æ–°åŠ è½½æ¨¡å‹
MODEL = None
CONFIGS = None
DEVICE = None
PREDICATE2ID = None
ID2TYPE = None


def get_configs():
    """é…ç½®å‚æ•°"""
    return {
        'r2id_path': 'relation2id.json',
        'pretrain_model_path': '../GuWen-Bert',
        'max_len': 128,
        'hidden_size': 768,
        'dropout': 0.1,
        'num_relations': 15,
        'seed': 42,
        'batch_size': 1,
        'model_save_dir': '../new_model',
        'model_filename': 'EPERR-sem+pos+rel.pth'
    }


def load_resources():
    """åŠ è½½æ¨¡å‹å’Œèµ„æºçš„è¾…åŠ©å‡½æ•°"""
    global MODEL, CONFIGS, DEVICE, PREDICATE2ID, ID2TYPE

    print(">>> æ­£åœ¨åˆå§‹åŒ–æœåŠ¡èµ„æº...")
    CONFIGS = get_configs()

    # 1. è®¾ç½®è®¾å¤‡
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    torch.manual_seed(CONFIGS['seed'])
    if torch.cuda.is_available():
        torch.cuda.manual_seed(CONFIGS['seed'])

    # 2. å‡†å¤‡æ˜ å°„å…³ç³»
    if os.path.exists(CONFIGS['r2id_path']):
        PREDICATE2ID = process.read_id(CONFIGS['r2id_path'])
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ° {CONFIGS['r2id_path']}ï¼Œä½¿ç”¨å†…ç½®æ˜ å°„è¡¨ã€‚")
        PREDICATE2ID = {
            "ä¸ºå®˜": 0, "ä¾é™„": 1, "çˆ¶å­": 2, "åŒåäº": 3, "å†›äº‹å¯¹æŠ—": 4,
            "æ€å®³": 5, "å…„å¼Ÿ": 6, "å‡ºç”Ÿåœ°": 7, "è‘¬åœ°": 8, "æœ‹å‹": 9,
            "éš¶å±äº": 10, "å»å¾€": 11, "ä½œ": 12, "ä½äº": 13, "å‡è¿": 14
        }
    ID2TYPE = {v: k for k, v in PREDICATE2ID.items()}

    # 3. åˆå§‹åŒ–æ¨¡å‹ç»“æ„
    MODEL = EPERR(
        model_path=CONFIGS['pretrain_model_path'],
        hidden_size=CONFIGS['hidden_size'],
        dropout=CONFIGS['dropout'],
        num_relations=CONFIGS['num_relations']
    )

    # 4. åŠ è½½æƒé‡
    model_path = os.path.join(CONFIGS['model_save_dir'], CONFIGS['model_filename'])
    if not os.path.exists(model_path):
        # å°è¯•å›é€€åˆ° best_model.pth
        fallback_path = os.path.join(CONFIGS['model_save_dir'], "best_model.pth")
        if os.path.exists(fallback_path):
            model_path = fallback_path
        else:
            raise FileNotFoundError(f"âŒ æ— æ³•æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_path} æˆ– {fallback_path}")

    MODEL.load_state_dict(torch.load(model_path, map_location=DEVICE))
    MODEL.to(DEVICE)
    MODEL.eval()
    print(f"âœ… æ¨¡å‹å·²åŠ è½½å®Œæ¯•: {model_path}")


# === æ¨ç†é€»è¾‘ ===
def run_inference(input_data):
    """æ‰§è¡Œå•æ¬¡æ¨ç†"""
    # 1. å ä½ç¬¦å¤„ç†ï¼šä¸ºæ•°æ®æ·»åŠ ä¸€ä¸ªå‡çš„ predicate æ ‡ç­¾ï¼Œé˜²æ­¢ preprocess æŠ¥é”™
    # è¿™é‡Œæˆ‘ä»¬å–æ˜ å°„è¡¨é‡Œçš„ç¬¬ä¸€ä¸ªé”®ä½œä¸ºå ä½ç¬¦
    dummy_key = list(PREDICATE2ID.keys())[0]
    input_data['predicate'] = dummy_key

    # å¦‚æœ preprocess éœ€è¦ relation å­—æ®µè€Œä¸æ˜¯ predicateï¼Œè¯·å–æ¶ˆä¸‹é¢è¿™è¡Œçš„æ³¨é‡Š
    input_data['relation'] = dummy_key

    # 2. è½¬ä¸º JSON å­—ç¬¦ä¸²åˆ—è¡¨ (æ¨¡æ‹Ÿæ–‡ä»¶è¯»å–)
    json_str = json.dumps(input_data, ensure_ascii=False)
    data_list = [json_str]

    try:
        # è°ƒç”¨ preprocess.Dataset
        # æ³¨æ„ï¼šæ¯æ¬¡è¯·æ±‚éƒ½åˆ›å»º Dataset å¯èƒ½ä¼šæœ‰è½»å¾®çš„æ€§èƒ½å¼€é”€(TokenizeråŠ è½½)ï¼Œ
        # ä½†è¿™æ˜¯ä¸ºäº†ä¸ä¿®æ”¹åŸå§‹ preprocess.py ä»£ç çš„æœ€ç¨³å¦¥æ–¹å¼ã€‚
        dataset = process.Dataset(
            data_list,
            PREDICATE2ID,
            DEVICE,
            CONFIGS['pretrain_model_path'],
            CONFIGS['max_len']
        )

        if len(dataset) == 0:
            return None, "æ•°æ®é¢„å¤„ç†åä¸ºç©ºï¼Œè¯·æ£€æŸ¥è¾“å…¥é•¿åº¦æˆ–æ ¼å¼"

        dataloader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=dataset.collate_fn)
    except Exception as e:
        return None, f"æ•°æ®é¢„å¤„ç†å¤±è´¥: {str(e)}"

    # 3. æ¨¡å‹å‰å‘ä¼ æ’­
    with torch.no_grad():
        for batch in dataloader:
            input_ids = batch["input_ids"].to(DEVICE)
            attention_mask = batch["attention_mask"].to(DEVICE)
            e1_mask = batch["e1_mask"].to(DEVICE)
            e2_mask = batch["e2_mask"].to(DEVICE)
            e1_pos = batch["e1_pos"].to(DEVICE)
            e2_pos = batch["e2_pos"].to(DEVICE)

            relation_logits = MODEL(
                input_ids, attention_mask,
                e1_mask, e2_mask,
                e1_pos, e2_pos
            )

            pred_id = torch.argmax(relation_logits, dim=-1).item()
            pred_relation = ID2TYPE.get(pred_id, "æœªçŸ¥å…³ç³»")

            return pred_relation, None

    return None, "æœªæ‰§è¡Œæ¨ç†å¾ªç¯"


# === è·¯ç”±å®šä¹‰ ===

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({"status": "healthy", "model_loaded": MODEL is not None})


@app.route('/predict', methods=['POST'])
def predict():
    """
    é¢„æµ‹æ¥å£
    æ¥å— JSON æ ¼å¼:
    {
        "text": "...",
        "subject_word": "...",
        "subject_pos": "...",
        "object_word": "...",
        "object_pos": "..."
    }
    """
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400

    data = request.json

    # ç®€å•çš„å‚æ•°æ ¡éªŒ
    required_fields = ["text", "subject_word", "subject_pos", "object_word", "object_pos"]
    missing_fields = [field for field in required_fields if field not in data]

    if missing_fields:
        return jsonify({"error": f"Missing fields: {missing_fields}"}), 400

    try:
        # æ‰§è¡Œé¢„æµ‹
        result, error = run_inference(data)

        if error:
            return jsonify({"status": "error", "message": error}), 500

        return jsonify({
            "status": "success",
            "data": {
                "text": data["text"],
                "subject": data["subject_word"],
                "object": data["object_word"],
                "predicted_relation": result
            }
        })

    except Exception as e:
        return jsonify({"status": "error", "message": str(e)}), 500


# === å¯åŠ¨å…¥å£ ===
if __name__ == '__main__':
    # å…ˆåŠ è½½æ¨¡å‹
    try:
        load_resources()
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        exit(1)

    # å¯åŠ¨ Flask
    # host='0.0.0.0' å…è®¸å¤–éƒ¨è®¿é—®ï¼Œport=5000 æ˜¯ç«¯å£å·
    print("ğŸš€ æœåŠ¡å·²å¯åŠ¨ï¼Œç›‘å¬ç«¯å£ 5000...")
    app.run(host='0.0.0.0', port=5000, debug=False)